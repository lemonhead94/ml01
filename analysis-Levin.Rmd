---
output:
  bookdown::pdf_document2:
    includes:
      in_header: latex/preamble.tex
      before_body: latex/titlepage.tex
    pandoc_args:
    - --csl
    - references/apa.csl
  bookdown::html_document2:
    pandoc_args:
    - --csl
    - references/apa.csl
  bookdown::word_document2:
    pandoc_args:
    - --csl
    - references/apa.csl
toc-title: Table of Contents
bibliography: references/references.bib
link-citations: yes
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \renewcommand{\headrulewidth}{0pt}
- \fancyfoot[C]{}
- \fancyfoot[R]{\thepage}
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, messages = FALSE)
packages <- c("bookdown", "dplyr", "ggplot2", "papeR", "kableExtra", "mgcv", 
              "rsample", "multcomp", "vip", "magicfor")
package.check <- lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
        install.packages(x, dependencies = TRUE)
        library(x, character.only = TRUE)
    }
})
```
\fancyhead[LR]{}
\pagenumbering{roman}

\newpage
\cleardoublepage
\pagenumbering{arabic}
\fancyhead[L]{Employee Attrition Model}
\fancyhead[R]{Machine Learning I}
# Introduction

Employees, according to @IBM_Developer_Challenge_2020, are the foundation of any business. Its success is largely determined by the quality of its employees and their ability to stay with the company. Organizations confront a number of issues as a result of staff attrition:

1. Training new personnel is costly in terms of both money and time.
2. Potential to lose experienced employees
3. Productivity impact
4. Profitability impact

Therefore, IBM data scientists created a fictitious data set as a challenge for data scientists. Among the data types are metrics such as education level, job satisfaction, and commute distance. The dataset can be found on the company's GitHub account [@IBM_Data_2019].

# Methodology

The following topics are layed out through out this paper:

1. Linear Models
2. Extending the Linear Model: Non-linearity
3. Extending the Linear Model: Generalised Linear Models
4. Support Vector Machines
5. Neural Networks
6. Optimisation

\newpage
# Data preparation
```{r import-data, echo = FALSE, results = FALSE}
# Working directory
setwd("~/HSLU/FS_22/Machine_learning/Groupwork/Github")
emp_attrition <- read.csv("emp_attrition.csv")
head(emp_attrition)
```

## Data Transformation and Sanity Check

The code for this part is left out from the PDF due to its length...
```{r formatting-data, echo = FALSE, results = FALSE}
# Age
names(emp_attrition)[names(emp_attrition) == "Ã¯..Age"] <- "Age"
summary(emp_attrition$Age)

# Attrition
emp_attrition$Attrition <- as.factor(emp_attrition$Attrition)
unique(emp_attrition$Attrition)

# BusinessTravel
emp_attrition$BusinessTravel <- as.factor(emp_attrition$BusinessTravel)
levels(emp_attrition$BusinessTravel) <- c("Rarely", "Frequently", "None")
emp_attrition$BusinessTravel <- relevel(emp_attrition$BusinessTravel, ref = "None")
unique(emp_attrition$BusinessTravel)

# DailyRate
summary(emp_attrition$DailyRate)

# Department
emp_attrition$Department <- as.factor(emp_attrition$Department)
levels(emp_attrition$Department) <- c("Sales", "R&D", "HR")
unique(emp_attrition$Department)

# DistanceFromHome
summary(emp_attrition$DistanceFromHome)

# Education
emp_attrition$Education <- as.factor(emp_attrition$Education)
levels(emp_attrition$Education) <- c("Below College", "College", "Bachelor", "Master", "Doctor")
unique(emp_attrition$Education)

# EducationField
emp_attrition$EducationField <- as.factor(emp_attrition$EducationField)
unique(emp_attrition$EducationField)

# EmployeeCount
unique(emp_attrition$EmployeeCount) # represents headcount which for all employee's in this dataset 1

# EmployeeNumber
summary(emp_attrition$EmployeeNumber) # internal employee id

# EnvironmentSatisfaction
emp_attrition$EnvironmentSatisfaction <- as.factor(emp_attrition$EnvironmentSatisfaction)
levels(emp_attrition$EnvironmentSatisfaction) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$EnvironmentSatisfaction)

# Gender
emp_attrition$Gender <- as.factor(emp_attrition$Gender)
unique(emp_attrition$Gender)

# HourlyRate
summary(emp_attrition$HourlyRate)

# JobInvolvement
emp_attrition$JobInvolvement <- as.factor(emp_attrition$JobInvolvement)
levels(emp_attrition$JobInvolvement) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$JobInvolvement)

# JobLevel
emp_attrition$JobLevel <- as.factor(emp_attrition$JobLevel)
unique(emp_attrition$JobLevel)

# JobRole
emp_attrition$JobRole <- as.factor(emp_attrition$JobRole)
unique(emp_attrition$JobRole)

# JobSatisfaction
emp_attrition$JobSatisfaction <- as.factor(emp_attrition$JobSatisfaction)
levels(emp_attrition$JobSatisfaction) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$JobSatisfaction)

# MaritalStatus
emp_attrition$MaritalStatus <- as.factor(emp_attrition$MaritalStatus)
unique(emp_attrition$MaritalStatus)

# MonthlyIncome
summary(emp_attrition$MonthlyIncome)

# MonthlyRate
summary(emp_attrition$MonthlyRate)

# NumCompaniesWorked
unique(emp_attrition$NumCompaniesWorked)

# Over18
unique(emp_attrition$Over18) # all employee's are above 18

# OverTime
emp_attrition$OverTime <- as.factor(emp_attrition$OverTime)
unique(emp_attrition$OverTime)

# PercentSalaryHike
summary(emp_attrition$PercentSalaryHike)

# PerformanceRating
emp_attrition$PerformanceRating <- as.factor(emp_attrition$PerformanceRating)
levels(emp_attrition$PerformanceRating) <- c("Excellent", "Outstanding")
unique(emp_attrition$PerformanceRating) # only employee's who perform 3 or 4

# RelationshipSatisfaction
emp_attrition$RelationshipSatisfaction <- as.factor(emp_attrition$RelationshipSatisfaction)
levels(emp_attrition$RelationshipSatisfaction) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$RelationshipSatisfaction)

# StandardHours
unique(emp_attrition$StandardHours) # the StandardHours for all employee's is 80, after check this means that this data has a 9/80 work schedule. Hence, employees work 80 hours in 9 days. So not a standard as 5/42 as in switzerland..

# StockOptionLevel
emp_attrition$StockOptionLevel <- as.factor(emp_attrition$StockOptionLevel)
unique(emp_attrition$StockOptionLevel)

# TotalWorkingYears
summary(emp_attrition$TotalWorkingYears)

# TrainingTimesLastYear
unique(emp_attrition$TrainingTimesLastYear)

# WorkLifeBalance
emp_attrition$WorkLifeBalance <- as.factor(emp_attrition$WorkLifeBalance)
levels(emp_attrition$WorkLifeBalance) <- c("Bad", "Good", "Better", "Best")
unique(emp_attrition$WorkLifeBalance)

# YearsAtCompany
summary(emp_attrition$YearsAtCompany)

# YearsInCurrentRole
summary(emp_attrition$YearsInCurrentRole)

# YearsSinceLastPromotion
summary(emp_attrition$YearsSinceLastPromotion)

# YearsWithCurrManager
summary(emp_attrition$YearsWithCurrManager)

labels(emp_attrition) <- colnames(emp_attrition)
labels(emp_attrition, which = c("Age", "BusinessTravel", "DailyRate", "DistanceFromHome", "EducationField", "EmployeeNumber", "EnvironmentSatisfaction", "HourlyRate", "JobInvolvement", "JobLevel", "JobRole", "JobSatisfaction", "MaritalStatus", "MonthlyIncome", "MonthlyRate", "NumCompaniesWorked", "OverTime", "PercentSalaryHike", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "TotalWorkingYears", "TrainingTimesLastYear", "WorkLifeBalance", "YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsWithCurrManager")) <- c("Age (years)", "Business Travel", "Daily Rate (salary per day)", "Distance From Home (1-29)", "Education Field", "Employee ID", "Environment Satisfaction", "Hourly Rate (salary per hour)", "Job Involvement", "Job Level (internal company hierachy 1-5)", "Job Role", "Job Satisfaction", "Marital Status", "Monthly Income", "Monthly Rate (salary per month)", "Number of Companies worked before starting this position", "has done over time", "% Salary Hike", "Performance Rating", "Relationship Satisfaction", "Stock Option Level (number of stocks an employee owns from 0-3)", "Total Working Years", "Number Of Trainings Done Last Year", "Work Life Balance", "Number Of Years At Company", "Number of Years In Current Role", "Number Of Years Since Last Promotion", "Number Of Years With Current Manager")
```

## Data Cleaning

```{r data-cleaning}
emp_attrition <- subset(emp_attrition, select = -c(EmployeeCount, StandardHours, Over18))
```

- EmployeeCount (represents the head count which is 1 for all employee, hence drop this)
- StandardHours (StandardHours for all employee's is 80, therefore this data has a 9/80 work schedule. Hence, employees work 80 hours in 9 days. So not a standard as 5/42 as in switzerland, we drop this)
- Over18 (all employee's are 18 or above and it's capured in age, hence drop this variable)

## Missing Value Check
```{r check-for-missing-values, echo = TRUE, results = FALSE}
# Do we have any missing values?
sapply(emp_attrition, function(x) all(is.na(x) | x == '' ))
```
There are no missing values in this dataset.

\newpage
## Overview of Dataset

```{r Overview, echo = TRUE, results = TRUE}
str(emp_attrition)
```

\newpage
# Exploration

## Histograms of variables 
In this section the distributions of the numerical variables are analyzed visually, also
in order to evaluate if a variable needs to be log transformed. Therefore, density histograms 
are displayed for each variable with log transformation(orange) and without transformation(blue).

```{r Dataset in scope, include=FALSE, message=FALSE, warning=FALSE}
# Dataset variables in scope
emp_attrition_scope <- emp_attrition[,c("Attrition", "Age", "BusinessTravel",
                                        "DistanceFromHome", "EnvironmentSatisfaction",
                                        "JobSatisfaction",
                                        "NumCompaniesWorked", "OverTime",
                                        "WorkLifeBalance", "YearsAtCompany",
                                        "YearsSinceLastPromotion",
                                        "YearsWithCurrManager")]

```

```{r Histograms, echo=FALSE, fig.show="hold", out.width = "33%"}
#Selecting numerical variables / extracting names
emp_attrition_numerical_only <- emp_attrition_scope %>% select_if(is.numeric)
names_numerical <- colnames(emp_attrition_numerical_only)

#Histogram plots loop
for (i in 1:ncol(emp_attrition_numerical_only)) {
  variable <- data.frame(matrix(nrow = 1470, ncol = 1))
  variable[,1] <- emp_attrition_numerical_only[, i]
  hist(variable[,1],
       probability = TRUE, breaks = 25,
       col = "blue", main = names_numerical[i])
  lines(density(variable[,1]), lwd = 2, col = "deeppink3")
  hist(log(variable[,1]), probability = TRUE, breaks = 25,
       col = "orange", main = names_numerical[i])
  lines(density(log(variable[,1])), lwd = 2, col = "deeppink3")
  variable <- data.frame(matrix(nrow = 1470, ncol = 1))
}

```
**Findings Histograms:**

- All variables, expect the variable "Years with current Manager", show some sort
of a right skeewed distribution and might be log transformed.

- The variable "Years with current Manager" seems to display a bimodal distribution
with two peaks, with the second peak showing right skeewedness. For a linear model, the
values of the variable could be split around the value 5 to analyse each peak 
separately, however, this might be most applicable if the residuals of the linear
model also display a bimodal distribution indicating a strong influence of the variable. 

- The variables "distance from home", "number of companies worked" and "years since 
last promotion" do not display a normal distribution after the log transformation.
This will be further considered when building a linear model. 
\newpage

# Training and Test Dataset 
```{r , include=FALSE, message=FALSE, warning=FALSE}
# Create training (80%) and test (20%)
set.seed(111)
emp_attrition_split <- initial_split(emp_attrition_scope, prop = 0.8, strata = "Attrition")
emp_attrition_train <- training(emp_attrition_split)
emp_attrition_test <- testing(emp_attrition_split)
```

\newpage

# Linear Regression
As it does not make sense to fit a Linear Model to a categorical variable such as Attrition (Levels: Yes/No), the Linear Models and also the General Additive Models will be fitted using YearsAtCompany as the dependent variable. We assume that the longer employees work for a company, the less attrition would actually happen. Therefore, the insight of this chapter might help to fit more complex model to the variable Attrition in the following chapters, but also indicate what leads employees to work longer for an employer. 

## Simple Linear Model
Before performing a Linear Regression Model, the reference level for the factor variables
are set to the level with the greatest n-count. Due to the length of the output, only the factor levels of the first two factor variables are displayed here.
```{r Linear Regression, echo=FALSE}
# Setup Data sets for LM / GAM part 
emp_attrition_train_lm <- emp_attrition_train
emp_attrition_test_lm <- emp_attrition_test
# Setting factor levels # Output n count of factor levels
emp_attrition_factors_only <- emp_attrition_train_lm %>% select_if(is.factor)
names_factor_variables <- colnames(emp_attrition_factors_only)
# Loop through factor variables
magic_for(print, silent = TRUE) # call magic_for()
for (i in 1:ncol(emp_attrition_factors_only)) {
  variable <- names_factor_variables[i]
  factor_levels <- table(emp_attrition_factors_only[,i])
  if (i < 3){ # printing first two iterations
    put(variable, factor_levels)}
  else {next}}
```

```{r Reference Levels, include=FALSE}
# Setting reference levels to factor with greatest n count if required
emp_attrition_train_lm$EnvironmentSatisfaction <- relevel(emp_attrition_train_lm$
                                                        EnvironmentSatisfaction,
                                                        ref = "High")
emp_attrition_train_lm$JobSatisfaction <- relevel(emp_attrition_train_lm$JobSatisfaction
                                              , ref = "High")
emp_attrition_train_lm$WorkLifeBalance <- relevel(emp_attrition_train_lm$WorkLifeBalance
                                              , ref = "Better")

```

The first Linear Model is performed including all variables without additional log transformation. As the model formula is included in the output, the code is omitted here.
```{r LM without log, echo=FALSE}
# Linear model without log transformation
lm.YearsAtCompany.0 <- lm(formula=YearsAtCompany ~ ., data = emp_attrition_train_lm)
lm.summary.0 <- summary(lm.YearsAtCompany.0)
lm.summary.0
```
**Findings LM Model .0:**

- According to the Adjusted R-squared value the model explains 68.48% of the variance of the dependent
variable.

- Variables with a significant influence on the dependet variable YearsAtCompany,
according to a significance level of 0.05: 

  + Age, NumCompaniesWorked, YearsSinceLastPromotion, YearsWithCurrManager

- The specific influence of each variable will be interpreted at a later stage for a better fitting model. 


## Linear Model with Log Transformation

In the next step the independent variables which displayed right skeewedness are log transformed for
a further Linear Model. As the log transformation did create infinity values from log(0) those values
are changed back to 0. No NaN values are created because there are no negative values in the
transformed variables. Created NaN values due to log transformation would most likely need to be deleted from a dataset if they can not be replaced by a reasonable value. Furthermore, the reference levels have to be set again for the newly created _log dataset.
```{r Log Linear Regression setup, results=FALSE}
# Log transformation of variables that seem to be right skeewed 
emp_attrition_log <- emp_attrition_train_lm
emp_attrition_log["Age"] <- log(emp_attrition_log["Age"]) 
emp_attrition_log["YearsAtCompany"] <- log(emp_attrition_log["YearsAtCompany"])
emp_attrition_log["YearsWithCurrManager"] <- log(emp_attrition_log["YearsWithCurrManager"])  
# Na's / -Inf values check after log transformation 
sum(is.na(emp_attrition_log))
sum(emp_attrition_log == "-Inf")
emp_attrition_log[emp_attrition_log == "-Inf"] <- 0
```
Output of the log transformed model:

```{r Log Linear Regression, echo=FALSE}
# Setting reference levels to factor with greatest n count if required
emp_attrition_log$EnvironmentSatisfaction <- relevel(emp_attrition_log$EnvironmentSatisfaction,
                                                     ref = "High")
emp_attrition_log$JobSatisfaction <- relevel(emp_attrition_log$JobSatisfaction, ref = "High")
emp_attrition_log$WorkLifeBalance <- relevel(emp_attrition_log$WorkLifeBalance, ref = "Better")

# LM All variables, incl. log transformation
lm.YearsAtCompany.1 <- lm(formula = YearsAtCompany ~ ., data = emp_attrition_log)
lm.summary.1 <- summary(lm.YearsAtCompany.1)
lm.summary.1
```
**Findings LM Models .1 including log-transformation:**

- Variables with a significant influence on the dependet variable YearsAtCompany,
according a significance level of 0.05: 

  + Attrition, Age, NumCompaniesWorked, YearsSinceLastPromotion, YearsWithCurrManager.
  + Compared to the previous model the variable Attrition became additionally significant.

- According to the Adjusted R-squared value, the model explains 71,98% of the variance of the 
dependent variable displaying an increase of 3.50% compared to the previous model without log transformation.

- Interestingly, the categorical variables, EnvironmentSatisfaction, WorkLifeBalanceGood,
display almost significant p-values for at least one factor level and will be kept for further modelling too.

- The variable YearsWithCurrentManager was log transformed due to the formely 
detected right skeewedness of the second peak, which can be reduced by this procedure. Furthermore, it increased also the adjusted R-Squared value of the model. 

- The variables DistanceFromHome, NumberOfCompaniesWorked and YearsSinceLastPromotion are not log transformed because this decreased the obtained Adjusted R-squared value in a trial. 

## Residual Analysis LM Models

**Without log transformation: **

- *Resiudals vs. fitted plot*: The spread of residuals seems to be higher for higher fitted values. 
Therefore, the normal distributions should be further questioned. 

- *QQ-Plot*: The strayed residuals around higher and lower values indicate that they might not 
be normally distributed.

- *Density plot*: As the residuals are mainly bell shaped, but also displaying right
skeewedness, the normal distribution will still be assumed. Furthermore, the formerly mentioned binomial
distribution of the variable YearsWithCurrentManager seems not to influence 
the distribution of the residuals heavily. Therefore, the two peaks of the variable
will not be analyzed separately nor will the data of the variable be split between
the peaks. A split of the dataset would of course also have further implications
which can be avoided in this analysis. 

```{r , fig.show="hold", out.width = "33%", echo=FALSE}
# Without log transformation # get list of residuals
lm.YearsAtCompany.0_residuals <- resid(lm.YearsAtCompany.0)
#produce residual vs. fitted plot
plot(fitted(lm.YearsAtCompany.0), lm.YearsAtCompany.0_residuals)
abline(0,0) #add a horizontal line at 0 
#create Q-Q plot for residuals
qqnorm(lm.YearsAtCompany.0_residuals)
qqline(lm.YearsAtCompany.0_residuals)#add a straight diagonal line to the plot
 
#Create density plot of residuals
plot(density(lm.YearsAtCompany.0_residuals))

```
**With log transformation:**

- *Residuals vs. fitted plot*: The spread of residuals for higher fitted values was reduced compared to the model without log transformation. However, the opposite can be observed for lower fitted values. 

- *QQ-Plot*: In this plot the residuals seem better distributed but still strayed
for higher values. For lower values the assumption of normal distribution seems less appropriate now. 

- *Density plot*: The bell shape is still somehow given, the length of the tails got reduced relatively to the scale. 

```{r, fig.show="hold", out.width = "33%", echo=FALSE}
# With log transformation
# get list of residuals
lm.YearsAtCompany.1_residuals <- resid(lm.YearsAtCompany.1)

#produce residual vs. fitted plot
plot(fitted(lm.YearsAtCompany.1), lm.YearsAtCompany.1_residuals)
abline(0,0) #add a horizontal line at 0 

#create Q-Q plot for residuals
qqnorm(lm.YearsAtCompany.1_residuals)
qqline(lm.YearsAtCompany.1_residuals)#add a straight diagonal line to the plot
 
#Create density plot of residuals
plot(density(lm.YearsAtCompany.1_residuals))

```
\newpage

## Final Linear Model and Verification

**Final Linear Model:** 

For the Final Linear Model only the formerly significant variables are kept, including categorical variables that did display at least one almost significant level. 

```{r Linear Regression selection, echo=FALSE}
# Significant variables, including categorical variable with at least one factor 
# level close to significance level
lm.YearsAtCompany.2 <- lm(YearsAtCompany ~ Attrition +
                                           Age + 
                                           EnvironmentSatisfaction +
                                           NumCompaniesWorked + 
                                           WorkLifeBalance + 
                                           YearsSinceLastPromotion +
                                           YearsWithCurrManager,
                                           data = emp_attrition_log)
lm.summary.2 <- summary(lm.YearsAtCompany.2)
lm.summary.2
```

**Interpretation:**

- Adjusted R-squared value: The model is explaining 72.08% of the variance of the dependent 
variable YearsAtCompany. Compared to the former model including all variables this accounts for a small increase of 0.01% by omitting four variables. 

- Intercept: YearsAtCompany if all other variables were 0 or at the reference level. 
Given variables such as Age, it is pointless to interpret the intercept for this model. 

**Interpretation of log transformed predictors on log transformed dependent variable:**

- Age: The dependent variable, YearsatCompany, increases by 0.37% years if the Age of an 
employee increases by 1%. If for example a 40 years old and a 44 years old employee 
are compared (+10%), the older employee is expected to have worked 3.70% longer at the company. 

- YearsWithCurrManager: The dependent variable, YearsAtCompany, increases by 0.75% if the independent variable increases by 1%. It is not surprising that people seem to prefer consictency in their direct management. 

**Interpretation of numerical predictors on log transformed dependent variable:**

- NumCompaniesWorked: The dependent variable, YearsAtCompany, decreases by -2.34% if the 
independent variable increases by 1 company. People who changed their employer often in the past might continue to do so. 

- YearsSinceLastPromotion: The dependent variable, YearsAtCompany, increases by 5.50% if 
the independent variable increases by 1 year. People who might be waiting/expecting a promotion are likely to work longer for a company. 

**Interpretation of categorical predictors on log transformed dependent variable, relevant levels only:**

- EnvironmentSatisfaction: The dependent variable, YearsAtCompany, decreases by 7.03% if the EnvironmentSatisfaction is "low", compared to the reference level "high". People with low EnvironmentSatisfaction are likely to leave the company sooner compared to people with high EnvironmentSatisfaction. 

- WorkLifeBalance: The dependent variable, YearsAtCompany, increases by 6.11% respectively
by 8.98% if the balance is "good" or even "best", compared to the reference level "better". The better the WorkLifeBalance of employees, the longer they seem to keep working for the company. 

- Attrition: The dependent variable, YearsAtCompany, decreases by 13.72% if an employee left the company. The decrease is not surprising but does not provide much additional insights with the available information. 

**Variable importance plot:**

In the following plot the variables are sorted by importance, variables that influence the dependent variable YearsAtCompany positively are colored cyan, variables that influence it negatively are colored red.

```{r, echo=FALSE, fig.show="hold", out.width="75%",out.height="50%"}
# Variable importance plot
vip(lm.YearsAtCompany.2, mapping = aes_string(fill = "Sign"))
```
\newpage

**Verification:**

As a first verification step a strict model is fitted, only including the variables below the significance level 0.05.

```{r, echo=FALSE}
# Strict model based on model .2
lm.YearsAtCompany.3 <- update(lm.YearsAtCompany.2, .~. - EnvironmentSatisfaction 
                              - WorkLifeBalance)
lm.summary.3 <- summary(lm.YearsAtCompany.3)
lm.summary.3
```

**Interpretation:**

- Only slight decrease of adjusted R-squared compared to the previous model by excluding 3 variables.

- However, when looking at the "Residual Sums of Squares" (RSS) in the *Analysis of Variance Table* below it becomes apparent that the previous model did explain slightly more of the variance of the dependent variable YearsAtCompany. Therefore, the more complex final model will be investigated further in the next section using a General Additive Models. 

```{r, echo=FALSE}
# Comparison
anova(lm.YearsAtCompany.2, lm.YearsAtCompany.3)
```

**Verification of the final model with the test data set:**

To test the final model with the test data, the test data set is equivalently transformed as the training data set. This includes the log transformation of 3 variables, including the dependent variable, setting infinity values to 0 and setting the reference level to the level with the greatest n-count.

```{r Verification LM, include=FALSE}
# Verification of model .2 with test data
# Log transformation
emp_attrition_test_lm["Age"] <- log(emp_attrition_test_lm["Age"]) 
emp_attrition_test_lm["YearsAtCompany"] <- log(emp_attrition_test_lm["YearsAtCompany"])
emp_attrition_test_lm["YearsWithCurrManager"] <- log(emp_attrition_test_lm["YearsWithCurrManager"])  
# Na's / -Inf values check after log transformation # Back to 0
sum(is.na(emp_attrition_test_lm)) # 0
sum(emp_attrition_test_lm == "-Inf") #240
emp_attrition_test_lm[emp_attrition_test_lm == "-Inf"] <- 0
# Setting reference levels
emp_attrition_test_lm$EnvironmentSatisfaction <- relevel(emp_attrition_test_lm$
                                                      EnvironmentSatisfaction,
                                                      ref = "High")
emp_attrition_test_lm$WorkLifeBalance <- relevel(emp_attrition_test_lm$WorkLifeBalance,
                                              ref = "Better")
```
```{r Verification LM Test data, echo=FALSE}
# Fitting Model
lm.YearsAtCompany.test <- update(lm.YearsAtCompany.2, data = emp_attrition_test_lm)
lm.summary.test <- summary(lm.YearsAtCompany.test)
lm.summary.test
```

**Interpretation:**

- The model reaches a slighty higher Adjusted R-squared value of 73.10% applied on the test data set.

- However, the variable Attrition ist just barely not significant anymore when considering the 0.05 significance level and also the other categorical variables loose in significance even more strongly. 

- Overall, the model seems to be still applicable to the test set, however, as the test data set is significantly smaller than the training data set, some effects seem to fade. 

# General Additive Model

Generalised Additive Models (GAMs) are an adaptation that allows to model non-linear data while maintaining explainability. In a first step the relationship between the dependent variable YearsAtCompany with the independent variables are analyzed visually and interpreted to verify whether a smooth term, e.g. for a quadratic or cubic relationship, would need to be included in a model. As it is an extension of the linear model, the variables Age, YearsAtCompany and YearsWithCurrentManager are kept as log transformed variables. 

```{r GAM Exploration YearsAtCompany, warning=FALSE, message=FALSE, echo=FALSE, fig.show="hold", out.width = "33%"}
# Dataset Numerical for visualisation
emp_attrition_gam <- emp_attrition_log %>% select_if(is.numeric)
names_variables <- colnames(emp_attrition_gam)
# Exploration regarding relationship with dependent variable 
magic_for(print, silent = FALSE) 
for (i in 1:6){
  if (i == 4) { next }
  else{
  variable <- data.frame(matrix(nrow = 1175, ncol = 2))
  variable[,1] <- emp_attrition_gam[,4]
  variable[,2] <- emp_attrition_gam[,i]
  print(ggplot(data = variable,
          mapping = aes(y = variable[,1],
          x = variable[,2])) +
          geom_point() +
          geom_smooth(method = "gam") +
          ggtitle(names_variables[i]) +
          xlab(names_variables[i]) +
          ylab(names_variables[4]))}
}
```

**Interpretation of relationship of YearAtCompany ~ Variable:**

- Age: The relationship might be quadratic. 

- DistancefromHome: The relationship seems to be constant. It therefore does not surprise that this variable was excluded in the previous linear model. It will be excluded from the General Additive Model as well. 

- NumCompaniesWorked: The relationship might be quadratic.

- YearSinceLastPromotion: The relationship seems to be rather complex than linear.

- YearsWithCurrManager: The relationship seems to be more or less linear but with a few imperfections.

**General Additive model with smooth terms:**

When the General Additive model is fitted to the same data set as the final model, assuming a "Gaussian" distribution, it returns the same output as for the final linear model. Therefore, we include smooth terms for the numerical variables in the following model. When testing including smooth terms variable by variable, it did increase the Adjusted R-squared value each time. By design, the model does choose the appropriate degree of complexity for the smooth terms itself as it is unknown to the user in most cases. 

```{r, echo=FALSE}
# General Additive Model; YearsAtCompany
gam.01 <- gam(YearsAtCompany ~  Attrition +
                                s(Age) +
                                EnvironmentSatisfaction +
                                s(NumCompaniesWorked) +
                                WorkLifeBalance +
                                s(YearsSinceLastPromotion) +
                                s(YearsWithCurrManager), 
                                data = emp_attrition_log,
                                family = "gaussian")

summary(gam.01)
```
**Interpretation:**

- The model reaches an Adjusted R squared value of 74.20%, which is slightly higher as the final linear model. 

- Variables with a significant effect on the dependent variable according to a significance level of 0.05:

  + Attrition, Age, NumCompaniesWorked, YearsSinceLastPromotion and YearsWithCurrentManager just as in     the final linear model. 

- For the numerical predictors Age, NumCompaniesWorked, YearsSinceLastPromotion and YearsWithCurrentManager, there is a strong evidence, that the variables have a non-linear effect on the dependent variable, according to the estimated degrees of freemdom (edf). A edf of 1 would indicate a linear relationship.

- As there seem to be strong non-linear effects, the influence of the numerical variables can not be interpreted as simple as for the linear model and will not be regarded here. 

In the next step this General Additive Model is verified by using the test-dataset, for which the log transformation and setting of reference levels was perfomed at an earlier stage.  

```{r, echo=FALSE}
# General Additive Model; YearsAtCompany, Test data
gam.test <- update(gam.01, data = emp_attrition_test_lm) 
                          
summary(gam.test)
```

**Interpretation:**

- The Adjusted R-squared value is close to the equivalent value of the GAM performed on the training data set. 

- However, the variable Attrition is not significant anymore if a significance level of 0.05 is applied, along with the categorical variables EnvironmentSatisfaction and WorkLifeBalance loosing in significance too. The same effects were noticed when testing the final linear model on the smaller test data set. 

- Interestingly, the smoothed numerical variables are still significant but display quite different edf values. For the variable YearsSinceLastPromotion a simple linear relationship would have been adequate for the test model, altough, a smooth term seemed appropriate in the trial for the previous General Additive Model.

**Evaluation GAM vs. Final Linear Model:**

Overall, the general additive model performs slighty better on the training dataset and also when applied to the test dataset, if measured by the returned Adjusted R-squared values. Similar effects are displayed for the fading of influence of the categorical variables Attrition, EnvironmentSatisfaction and WorkLifeBalance on the dependent variable YearsAtCompany for both approaches, when fitted to the smaller test dataset. The smoothed terms in the General Additive model seem to fit the numerical variables slightly better, however, taking into account that the effects of the variables can be interpeted quite straightforward in the linear model, the final linear model seems to fit the attrition data sets sufficiently. 

\newpage
# Conclusion

\newpage
# Session Information {-}

```{r session-info}
#sessionInfo()
```

\newpage
# References

