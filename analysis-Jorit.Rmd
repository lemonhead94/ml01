---
output:
  bookdown::pdf_document2:
    includes:
      in_header: latex/preamble.tex
      before_body: latex/titlepage.tex
    pandoc_args:
    - --csl
    - references/apa.csl
  bookdown::html_document2:
    pandoc_args:
    - --csl
    - references/apa.csl
  bookdown::word_document2:
    pandoc_args:
    - --csl
    - references/apa.csl
toc-title: Table of Contents
bibliography: references/references.bib
link-citations: yes
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \renewcommand{\headrulewidth}{0pt}
- \fancyfoot[C]{}
- \fancyfoot[R]{\thepage}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, messages = FALSE)
packages <- c("bookdown", "dplyr", "ggplot2", "papeR", "kableExtra", "mgcv", "caret", "vip", "rsample", "tidyverse", "yardstick", "arm", "pROC")
package.check <- lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
        install.packages(x, dependencies = TRUE)
        library(x, character.only = TRUE)
    }
})
```

```{=tex}
\fancyhead[LR]{}
\pagenumbering{roman}
```
```{=tex}
\newpage
\cleardoublepage
\pagenumbering{arabic}
\fancyhead[L]{Employee Attrition Model}
\fancyhead[R]{Machine Learning I}
```
# Introduction

Employees, according to @IBM_Developer_Challenge_2020, are the foundation of any business. Its success is largely determined by the quality of its employees and their ability to stay with the company. Organizations confront a number of issues as a result of staff attrition:

1.  Training new personnel is costly in terms of both money and time.
2.  Potential to lose experienced employees
3.  Productivity impact
4.  Profitability impact

Therefore, IBM data scientists created a fictitious data set as a challenge for data scientists. Among the data types are metrics such as education level, job satisfaction, and commute distance. The dataset can be found on the company's GitHub account [@IBM_Data_2019].

# Methodology

The following topics are layed out through out this paper:

1.  Linear Models
2.  Extending the Linear Model: Non-linearity (GAM)
3.  Extending the Linear Model: Generalised Linear Models (GLM)
- poisson as well as binominal
4.  Support Vector Machines
5.  Neural Networks
6.  Optimisation

\newpage

# Data preparation

```{r import-data, echo = FALSE, results = FALSE}
emp_attrition <- read.csv("./data/emp_attrition.csv")
head(emp_attrition)
```

## Data Transformation and Sanity Check

The code for this part is left out from the PDF due to its length...

```{r formatting-data, echo = FALSE, results = FALSE}
# Age
summary(emp_attrition$Age)

# Attrition
emp_attrition$Attrition <- as.factor(emp_attrition$Attrition)
unique(emp_attrition$Attrition)

# BusinessTravel
emp_attrition$BusinessTravel <- as.factor(emp_attrition$BusinessTravel)
levels(emp_attrition$BusinessTravel) <- c("Rarely", "Frequently", "None")
emp_attrition$BusinessTravel <- relevel(emp_attrition$BusinessTravel, ref = "None")
unique(emp_attrition$BusinessTravel)

# DailyRate
summary(emp_attrition$DailyRate)

# Department
emp_attrition$Department <- as.factor(emp_attrition$Department)
levels(emp_attrition$Department) <- c("Sales", "R&D", "HR")
unique(emp_attrition$Department)

# DistanceFromHome
summary(emp_attrition$DistanceFromHome)

# Education
emp_attrition$Education <- as.factor(emp_attrition$Education)
levels(emp_attrition$Education) <- c("Below College", "College", "Bachelor", "Master", "Doctor")
unique(emp_attrition$Education)

# EducationField
emp_attrition$EducationField <- as.factor(emp_attrition$EducationField)
unique(emp_attrition$EducationField)

# EmployeeCount
unique(emp_attrition$EmployeeCount) # represents headcount which for all employee's in this dataset 1

# EmployeeNumber
summary(emp_attrition$EmployeeNumber) # internal employee id

# EnvironmentSatisfaction
emp_attrition$EnvironmentSatisfaction <- as.factor(emp_attrition$EnvironmentSatisfaction)
levels(emp_attrition$EnvironmentSatisfaction) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$EnvironmentSatisfaction)

# Gender
emp_attrition$Gender <- as.factor(emp_attrition$Gender)
unique(emp_attrition$Gender)

# HourlyRate
summary(emp_attrition$HourlyRate)

# JobInvolvement
emp_attrition$JobInvolvement <- as.factor(emp_attrition$JobInvolvement)
levels(emp_attrition$JobInvolvement) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$JobInvolvement)

# JobLevel
emp_attrition$JobLevel <- as.factor(emp_attrition$JobLevel)
unique(emp_attrition$JobLevel)

# JobRole
emp_attrition$JobRole <- as.factor(emp_attrition$JobRole)
unique(emp_attrition$JobRole)

# JobSatisfaction
emp_attrition$JobSatisfaction <- as.factor(emp_attrition$JobSatisfaction)
levels(emp_attrition$JobSatisfaction) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$JobSatisfaction)

# MaritalStatus
emp_attrition$MaritalStatus <- as.factor(emp_attrition$MaritalStatus)
unique(emp_attrition$MaritalStatus)

# MonthlyIncome
summary(emp_attrition$MonthlyIncome)

# MonthlyRate
summary(emp_attrition$MonthlyRate)

# NumCompaniesWorked
unique(emp_attrition$NumCompaniesWorked)

# Over18
unique(emp_attrition$Over18) # all employee's are above 18

# OverTime
emp_attrition$OverTime <- as.factor(emp_attrition$OverTime)
unique(emp_attrition$OverTime)

# PercentSalaryHike
summary(emp_attrition$PercentSalaryHike)

# PerformanceRating
emp_attrition$PerformanceRating <- as.factor(emp_attrition$PerformanceRating)
levels(emp_attrition$PerformanceRating) <- c("Excellent", "Outstanding")
unique(emp_attrition$PerformanceRating) # only employee's who perform 3 or 4

# RelationshipSatisfaction
emp_attrition$RelationshipSatisfaction <- as.factor(emp_attrition$RelationshipSatisfaction)
levels(emp_attrition$RelationshipSatisfaction) <- c("Low", "Medium", "High", "Very High")
unique(emp_attrition$RelationshipSatisfaction)

# StandardHours
unique(emp_attrition$StandardHours) # the StandardHours for all employee's is 80, after check this means that this data has a 9/80 work schedule. Hence, employees work 80 hours in 9 days. So not a standard as 5/42 as in switzerland..

# StockOptionLevel
emp_attrition$StockOptionLevel <- as.factor(emp_attrition$StockOptionLevel)
unique(emp_attrition$StockOptionLevel)

# TotalWorkingYears
summary(emp_attrition$TotalWorkingYears)

# TrainingTimesLastYear
unique(emp_attrition$TrainingTimesLastYear)

# WorkLifeBalance
emp_attrition$WorkLifeBalance <- as.factor(emp_attrition$WorkLifeBalance)
levels(emp_attrition$WorkLifeBalance) <- c("Bad", "Good", "Better", "Best")
unique(emp_attrition$WorkLifeBalance)

# YearsAtCompany
summary(emp_attrition$YearsAtCompany)

# YearsInCurrentRole
summary(emp_attrition$YearsInCurrentRole)

# YearsSinceLastPromotion
summary(emp_attrition$YearsSinceLastPromotion)

# YearsWithCurrManager
summary(emp_attrition$YearsWithCurrManager)

labels(emp_attrition) <- colnames(emp_attrition)
labels(emp_attrition, which = c("Age", "BusinessTravel", "DailyRate", "DistanceFromHome", "EducationField", "EmployeeNumber", "EnvironmentSatisfaction", "HourlyRate", "JobInvolvement", "JobLevel", "JobRole", "JobSatisfaction", "MaritalStatus", "MonthlyIncome", "MonthlyRate", "NumCompaniesWorked", "OverTime", "PercentSalaryHike", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "TotalWorkingYears", "TrainingTimesLastYear", "WorkLifeBalance", "YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsWithCurrManager")) <- c("Age (years)", "Business Travel", "Daily Rate (salary per day)", "Distance From Home (1-29)", "Education Field", "Employee ID", "Environment Satisfaction", "Hourly Rate (salary per hour)", "Job Involvement", "Job Level (internal company hierachy 1-5)", "Job Role", "Job Satisfaction", "Marital Status", "Monthly Income", "Monthly Rate (salary per month)", "Number of Companies worked before starting this position", "has done over time", "% Salary Hike", "Performance Rating", "Relationship Satisfaction", "Stock Option Level (number of stocks an employee owns from 0-3)", "Total Working Years", "Number Of Trainings Done Last Year", "Work Life Balance", "Number Of Years At Company", "Number of Years In Current Role", "Number Of Years Since Last Promotion", "Number Of Years With Current Manager")
```

## Data Cleaning

```{r data-cleaning}
emp_attrition <- emp_attrition %>% dplyr::select(-c(EmployeeCount, StandardHours, Over18))
```

-   EmployeeCount (represents the head count which is 1 for all employee, hence drop this)
-   StandardHours (StandardHours for all employee's is 80, therefore this data has a 9/80 work schedule. Hence, employees work 80 hours in 9 days. So not a standard as 5/42 as in switzerland, we drop this)
-   Over18 (all employee's are 18 or above and it's capured in age, hence drop this variable)

## Missing Value Check

```{r check-for-missing-values, echo = TRUE, results = FALSE}
# Do we have any missing values?
sapply(emp_attrition, function(x) all(is.na(x) | x == '' ))
```

There are no missing values in this dataset.

\newpage

## Overview of Dataset

```{r numeric-variable-table, echo = FALSE, message = FALSE, results='asis'}
kable(summarize(emp_attrition, type = "numeric"), 
      caption = "Summary Numeric Variables", format = "latex", booktabs = TRUE) %>%
  kable_styling(latex_options = "hold_position")
```

```{r factor-variable-table, echo = FALSE, message = FALSE, results='asis'}
summary.factors <- papeR::summarize(emp_attrition, type = "factor")
kable(list(summary.factors[1:33,], summary.factors[34:66,]), 
      caption = "Summary Factor Variables", format = "latex", booktabs = TRUE, row.names = FALSE) %>%
  kable_styling(latex_options = "hold_position", font_size = 5.8)
```

\newpage

## Splitting Dataset (Stratification)

There is significant class imbalance in the variable Attrition (84 / 16) as can be seen in Table 2, which makes sense since most employees want to work at the company. However it is important to stratify the train and test split so that we receive a more realist estimate on how our model is going to perform.

```{r, echo=TRUE, message=FALSE, warning=FALSE }
set.seed(111)
emp_attrition_split <- initial_split(emp_attrition, prop = 0.80, strata = "Attrition")
emp_attrition_train <- training(emp_attrition_split) # i.e. 986 / 189 = 5.22
emp_attrition_test  <- testing(emp_attrition_split) # i.e. 248 / 48 = 5.17
```

In this analysis we are splitting the data set with 80% training and 20% test / validation.
As can be observed above we have an almost equal ratio of yes to no in the training as well as the testing data set due to stratification.

# Exploration

\newpage

# Linear Regression

# Generalised Linear Models

## Simple Logistic Regression

```{r}
attrition_model1 <- glm(Attrition ~ OverTime, family = "binomial", data = emp_attrition)
summary(attrition_model1)$coefficients
```
Not unexpectedly overtime seems to play a relevant role. Indeed, its p-value is highly significant.

```{r attrition_vs_overtime, out.width = "50%", echo=FALSE}
ggplot(emp_attrition, aes(OverTime, attrition_model1$fitted.values, color = OverTime)) +
  geom_boxplot(show.legend = FALSE) +
  geom_rug(sides = "b", position = "jitter", alpha = 0.2, show.legend = FALSE) +
  labs(title="Attrition ~ OverTime", x="OverTime", y="Probability of Attrition")
```

```{r}
exp(coef(attrition_model1)["OverTimeYes"])
```

The odds of someone leaving the company with overtime are about ~3.8 times higher than the odds for no overtime in this simple model.


## Multiple logistic regression

```{r variable_importance_multiple_logistic_regression, echo=FALSE, message=FALSE, warning=FALSE, out.width = "50%" }
glm.model <- glm(Attrition ~ ., family = "binomial", data = emp_attrition_train)
vi(glm.model) %>%
  filter(Sign == 'POS') %>%
  ggplot(aes(x = Importance, y = reorder(Variable, +Importance))) + 
  geom_bar(stat = "identity", fill='#01bfc4') + theme(legend.position="none") + 
  ylab("")

vi(glm.model) %>%
  filter(Sign == 'NEG') %>%
  ggplot(aes(x = Importance, y = reorder(Variable, +Importance), fill = Sign)) + 
  geom_bar(stat = "identity") + theme(legend.position="none") + ylab("")
```

In the above plots we can observe the most important variables (Variable Importance) to predict employment attrition according to the absolute value of the z-statistic for each coefficient in the dataset. Moreover the importance of independent variables are colored to indicate increasing (blue) or decreasing (red) risk of employee attrition. We again observe that OverTime seems to be highly correlated with employee attrition in this data set. Moreover, EnviromentSatisfaction and JobSatisfaction seem to be also be critical, which would make sense since we are talking about employment attrition.

Based on the exploratory data analysis, the previous section as well as the above variable importance scores we are trying to fit a better multiple logistic regression model.

```{r multiple_logistic_regression_refined}
glm.model.2 <- glm(Attrition ~ OverTime + EnvironmentSatisfaction + NumCompaniesWorked + 
                     JobSatisfaction + BusinessTravel + DistanceFromHome + 
                     WorkLifeBalance + Age + YearsWithCurrManager + YearsSinceLastPromotion, 
                   family = "binomial", data = emp_attrition_train)
```

The new model seems to have quite a good fit with all independent variables having significant p-values.

```{r variable_importance_multiple_logistic_regression_refined, echo=FALSE}
vip(glm.model.2, num_features = 30, horizontal = TRUE, 
          mapping = aes_string(fill = "Sign"))
```
The new variable importance plot seems to have ranked Age a lot higher than before while overtime still seems to remain a large main effect. Thus, there might be interactions in these variable and we should start developing the model.

\newpage
## Model Development

The code for the model development is hidden since it is to large for this paper.

```{r model-development, echo=FALSE, results=FALSE, warning=FALSE}
glm.model.2 <- glm(Attrition ~ EnvironmentSatisfaction + NumCompaniesWorked + 
                     JobSatisfaction + BusinessTravel + DistanceFromHome + 
                     WorkLifeBalance + YearsWithCurrManager + 
                     YearsSinceLastPromotion + Age + OverTime +
                     # interactions of Age
                     Age:EnvironmentSatisfaction +
                     Age:NumCompaniesWorked +
                     Age:JobSatisfaction +
                     Age:BusinessTravel +
                     Age:DistanceFromHome +
                     Age:WorkLifeBalance +
                     Age:YearsWithCurrManager +
                     Age:YearsSinceLastPromotion +
                     Age:OverTime, 
                   family = "binomial", data = emp_attrition_train)

drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ . - EnvironmentSatisfaction:Age - NumCompaniesWorked:Age - DistanceFromHome:Age - WorkLifeBalance:Age - YearsSinceLastPromotion:Age)

glm.model.2 <- update(glm.model.2, . ~ . + OverTime:EnvironmentSatisfaction +
                     OverTime:NumCompaniesWorked +
                     OverTime:JobSatisfaction +
                     OverTime:BusinessTravel +
                     OverTime:DistanceFromHome +
                     OverTime:WorkLifeBalance +
                     OverTime:YearsWithCurrManager +
                     OverTime:YearsSinceLastPromotion)

drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ . - OverTime:EnvironmentSatisfaction
                     - OverTime:NumCompaniesWorked
                     - OverTime:JobSatisfaction
                     - OverTime:BusinessTravel
                     - OverTime:DistanceFromHome
                     - OverTime:WorkLifeBalance
                     - OverTime:YearsWithCurrManager
                     - OverTime:YearsSinceLastPromotion
                     - OverTime:Age
                     - BusinessTravel:Age)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + EnvironmentSatisfaction:NumCompaniesWorked
                     + EnvironmentSatisfaction:JobSatisfaction
                     + EnvironmentSatisfaction:BusinessTravel
                     + EnvironmentSatisfaction:DistanceFromHome
                     + EnvironmentSatisfaction:WorkLifeBalance
                     + EnvironmentSatisfaction:YearsWithCurrManager
                     + EnvironmentSatisfaction:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - EnvironmentSatisfaction:NumCompaniesWorked
                     - EnvironmentSatisfaction:JobSatisfaction
                     - EnvironmentSatisfaction:BusinessTravel
                     - EnvironmentSatisfaction:DistanceFromHome
                     - EnvironmentSatisfaction:WorkLifeBalance
                     - EnvironmentSatisfaction:YearsWithCurrManager
                     - EnvironmentSatisfaction:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + NumCompaniesWorked:NumCompaniesWorked
                     + NumCompaniesWorked:JobSatisfaction
                     + NumCompaniesWorked:BusinessTravel
                     + NumCompaniesWorked:DistanceFromHome
                     + NumCompaniesWorked:WorkLifeBalance
                     + NumCompaniesWorked:YearsWithCurrManager
                     + NumCompaniesWorked:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - NumCompaniesWorked:NumCompaniesWorked
                     - NumCompaniesWorked:JobSatisfaction
                     - NumCompaniesWorked:BusinessTravel
                     - NumCompaniesWorked:DistanceFromHome
                     - NumCompaniesWorked:WorkLifeBalance
                     - NumCompaniesWorked:YearsWithCurrManager
                     - NumCompaniesWorked:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + JobSatisfaction:NumCompaniesWorked
                     + JobSatisfaction:JobSatisfaction
                     + JobSatisfaction:BusinessTravel
                     + JobSatisfaction:DistanceFromHome
                     + JobSatisfaction:WorkLifeBalance
                     + JobSatisfaction:YearsWithCurrManager
                     + JobSatisfaction:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - JobSatisfaction:BusinessTravel
                     - JobSatisfaction:DistanceFromHome
                     - JobSatisfaction:YearsWithCurrManager
                     - JobSatisfaction:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + BusinessTravel:NumCompaniesWorked
                     + BusinessTravel:JobSatisfaction
                     + BusinessTravel:DistanceFromHome
                     + BusinessTravel:WorkLifeBalance
                     + BusinessTravel:YearsWithCurrManager
                     + BusinessTravel:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - BusinessTravel:NumCompaniesWorked
                     - BusinessTravel:DistanceFromHome
                     - BusinessTravel:WorkLifeBalance
                     - BusinessTravel:YearsWithCurrManager
                     - BusinessTravel:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + DistanceFromHome:NumCompaniesWorked
                     + DistanceFromHome:JobSatisfaction
                     + DistanceFromHome:BusinessTravel
                     + DistanceFromHome:WorkLifeBalance
                     + DistanceFromHome:YearsWithCurrManager
                     + DistanceFromHome:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - DistanceFromHome:NumCompaniesWorked
                     - DistanceFromHome:JobSatisfaction
                     - DistanceFromHome:BusinessTravel
                     - DistanceFromHome:WorkLifeBalance
                     - DistanceFromHome:YearsWithCurrManager
                     - DistanceFromHome:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + WorkLifeBalance:NumCompaniesWorked
                     + WorkLifeBalance:JobSatisfaction
                     + WorkLifeBalance:BusinessTravel
                     + WorkLifeBalance:YearsWithCurrManager
                     + WorkLifeBalance:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - WorkLifeBalance:NumCompaniesWorked
                     - WorkLifeBalance:BusinessTravel
                     - WorkLifeBalance:YearsWithCurrManager
                     - WorkLifeBalance:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + YearsWithCurrManager:NumCompaniesWorked
                     + YearsWithCurrManager:JobSatisfaction
                     + YearsWithCurrManager:BusinessTravel
                     + YearsWithCurrManager:YearsSinceLastPromotion)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - YearsWithCurrManager:NumCompaniesWorked
                     - YearsWithCurrManager:JobSatisfaction
                     - YearsWithCurrManager:BusinessTravel)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     + YearsSinceLastPromotion:NumCompaniesWorked
                     + YearsSinceLastPromotion:JobSatisfaction
                     + YearsSinceLastPromotion:BusinessTravel
                     + YearsSinceLastPromotion:DistanceFromHome
                     + YearsSinceLastPromotion:WorkLifeBalance
                     + YearsSinceLastPromotion:YearsWithCurrManager)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ .
                     - YearsSinceLastPromotion:NumCompaniesWorked
                     - YearsSinceLastPromotion:JobSatisfaction
                     - YearsSinceLastPromotion:BusinessTravel
                     - YearsSinceLastPromotion:DistanceFromHome
                     - YearsSinceLastPromotion:WorkLifeBalance
                     - YearsSinceLastPromotion:YearsWithCurrManager)
drop1(glm.model.2, test = "F")

glm.model.2 <- update(glm.model.2, . ~ . - Age:YearsWithCurrManager)
drop1(glm.model.2, test = "F")
```
By using the drop1 function we have added and remove significant interactions.
Finally we end up with significant interaction inclusion of JobSatifaction with Age, Number of Companies Worked for, Work Life Balance and Business Travel Frequency.

```{r}
final.glm <- glm(Attrition ~ EnvironmentSatisfaction + NumCompaniesWorked + JobSatisfaction + 
    BusinessTravel + DistanceFromHome + OverTime + YearsAtCompany + 
    PercentSalaryHike + WorkLifeBalance + Age + YearsWithCurrManager + 
    YearsSinceLastPromotion + 
    JobSatisfaction:Age + JobSatisfaction:NumCompaniesWorked + 
    JobSatisfaction:WorkLifeBalance + JobSatisfaction:BusinessTravel, family = "binomial", data = emp_attrition)
# exp(coef(final.glm))
```

**Interpretation of the Logistic Regression**

The odds of someone leaving the company 

  - with overtime are about ~5.6 times higher than the odds for no overtime
  
  - with a 'very high' environment satisfaction are lower than the ones of low environment satisfaction by ~0.31 times.
  - with a 'high' environment satisfaction are lower than the ones of low environment satisfaction by ~0.37 times. 
  - with a 'medium' environment satisfaction are lower than the ones of low environment satisfaction by ~0.38 times. 
  
  - are multiplied by 1.19 i.e increasing for each additional company the employee has worked for
  
  - with a 'very high' job satisfaction are lower than the ones of low job satisfaction by ~0.009 times.
  - with a 'high' job satisfaction are lower than the ones of low job satisfaction by ~0.12 times.
  - with a 'medium' job satisfaction are lower than the ones of low job satisfaction by ~0.04 times.
  
  - having to travel for work 'rarely' increases the risk by ~1.38 times
  - having to travel for work 'frequently' increases the risk by ~2.04 times
  
  - are multiplied by 1.03 i.e increasing for each unit of distance between work and home
  
  - are multiplied by 0.97 i.e slightly decreasing for each additional year the employee has worked at the company
  
  - are multiplied by 0.99 i.e slightly decreasing for each percentage in salary hike an employee has received
  
  - with a 'good' work life balance score are lower than the ones of 'bad' work life balance score by ~0.11 times.
  - with a 'better' work life balance score are lower than the ones of 'bad' work life balance score by ~0.11 times.
  - with a 'best' work life balance score are lower than the ones of 'bad' work life balance score by ~0.12 times.

  - are multiplied by 0.9 i.e decreasing for each additional year of age an employee has
  
  - are multiplied by 0.86 i.e decreasing for each additional year an employee has worked for the same manager
  
  - are multiplied by 1.17 i.e increasing for each year an employee has not received a promotion
  
**Summary**

*Overtime* seems to increase the risk of attrition by almost six times as much and is by far the most highly critical attribute on whether an employee continues to stay at the company or not. 
It does not seem to matter to much how well the *job environment* score is as long as it is above 'low' as they almost equally decrease the risk of someone leaving the company. The amount of *business traveling* an employee has to do seems to play an important role as well as the risk of someone quitting the company increases by two times if said person has frequently travel for work. *Age* seems to play a role as well as young employee seem to leave the company more often than old employees. Employee seem to leave the company less often if they are not bound to re-organisations i.e. have the same *manager* for an extended period of time. For each year an employee has not received a *promotion* the risk of them leaving increases.


## Confusion Matrix

```{r confusion-matrix, echo=FALSE, message=FALSE, warning=FALSE, out.width = "33%"}
set.seed(111)
cv_glm.model <- train(
  Attrition ~ ., 
  data = emp_attrition_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10) # 10 fold cross validation
)

emp_attrition_results <- emp_attrition_test %>%
        mutate(`Logistic regression` = predict(cv_glm.model, emp_attrition_test))

# confusion matrix
conf_mat(emp_attrition_results, truth = Attrition, estimate = `Logistic regression`) %>% 
  autoplot(type = "heatmap") + ggplot2::ggtitle("1. All Predictors")

cv_glm.model.2 <- train(
  Attrition ~ EnvironmentSatisfaction + NumCompaniesWorked + JobSatisfaction + 
    BusinessTravel + DistanceFromHome + OverTime + YearsAtCompany + 
    PercentSalaryHike + WorkLifeBalance + Age + YearsWithCurrManager + 
    YearsSinceLastPromotion, 
  data = emp_attrition_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10) # 10 fold cross validation
)

emp_attrition_results.2 <- emp_attrition_test %>%
        mutate(`Logistic regression` = predict(cv_glm.model.2, emp_attrition_test))

# confusion matrix
conf_mat(emp_attrition_results.2, truth = Attrition, estimate = `Logistic regression`) %>% 
  autoplot(type = "heatmap") + ggplot2::ggtitle("2. Multiple Logistic Regression w/o interactions")

cv_glm.model.3 <- train(
  Attrition ~ EnvironmentSatisfaction + NumCompaniesWorked + JobSatisfaction + 
    BusinessTravel + DistanceFromHome + OverTime + YearsAtCompany + 
    PercentSalaryHike + WorkLifeBalance + Age + YearsWithCurrManager + 
    YearsSinceLastPromotion + 
    JobSatisfaction:Age + JobSatisfaction:NumCompaniesWorked + 
    JobSatisfaction:WorkLifeBalance + JobSatisfaction:BusinessTravel, 
  data = emp_attrition_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10) # 10 fold cross validation
)

emp_attrition_results.3 <- emp_attrition_test %>%
        mutate(`Logistic regression` = predict(cv_glm.model.3, emp_attrition_test))

# confusion matrix
conf_mat(emp_attrition_results.3, truth = Attrition, estimate = `Logistic regression`) %>% 
  autoplot(type = "heatmap") + ggplot2::ggtitle("3. Multiple Logistic Regression w/ interactions")

cv_glm.model.0 <- train(
  Attrition ~ OverTime, 
  data = emp_attrition_train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10) # 10 fold cross validation
)
```

1. When looking at the first plot using cross validation & including all predictors we get the following scores.


    *Specificity* = True Negatives / (True Negatives + False Positives)

    - i.e. 237 / (10 + 237) = 0.95
    - 95% of the people not leaving the company were correctly identified by the Logistic Regression model.


    *Sensitivity* = True Positives / (True Positives + False Negatives)

    - i.e. 19 / (29 + 19) = 0.4
    - 40% of the people leaving the company were correctly identified by the Logistic Regression model.

2. Without interactions using a much simpler model we actually get a better specificity, but can only predict 23% of the people who are actually leaving the company. In other words the True Positive Rate which we are looking for is significantly worse.


    *Specificity* = 239 / (8 + 239) = 0.97
  
    - 97% of the people not leaving the company were correctly identified by the Logistic Regression model.


    *Sensitivity* = 11 / (37 + 11) = 0.23
  
    - 23% of the people leaving the company were correctly identified by the Logistic Regression model.

3. When including the interactions we are able to predict the True Positive Rate a bit better however we sacrifice some of the specificity


    *Specificity* = 235 / (12 + 235) = 0.95
  
    - 95% of the people not leaving the company were correctly identified by the Logistic Regression model.


    *Sensitivity* = 12 / (36 + 12) = 0.25
  
    - 25% of the people leaving the company were correctly identified by the Logistic Regression model.


## Receiver Operating Characteristics

```{r roc, echo=FALSE, message=FALSE, warning=FALSE, results='hide', fig.show='hold'}
set.seed(111)
cv_glm.probability <- predict(cv_glm.model, emp_attrition_train, type = "prob")$Yes
roc.info <- roc(emp_attrition_train$Attrition, cv_glm.probability, legacy.axes=TRUE)
roc.df <- data.frame(tpp=roc.info$sensitivities*100, 
                     fpp=(1-roc.info$specificities)*100,
                     thresholds=roc.info$thresholds)

# calculating the probability
cv_glm.probability.2 <- predict(cv_glm.model.2, emp_attrition_train, type = "prob")$Yes
cv_glm.probability.3 <- predict(cv_glm.model.3, emp_attrition_train, type = "prob")$Yes
cv_glm.probability.0 <- predict(cv_glm.model.0, emp_attrition_train, type = "prob")$Yes

# plotting ROC
par(pty = "s")
roc(emp_attrition_train$Attrition, cv_glm.probability, plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage", col="blue", print.auc=TRUE)
plot.roc(emp_attrition_train$Attrition, cv_glm.probability.3, percent=TRUE, col="#4daf4a", add=TRUE, print.auc=TRUE, print.auc.y=43)
plot.roc(emp_attrition_train$Attrition, cv_glm.probability.2, percent=TRUE, col="#e34a33", add=TRUE, print.auc=TRUE, print.auc.y=36.5)
plot.roc(emp_attrition_train$Attrition, cv_glm.probability.0, percent=TRUE, col="#1c9099", add=TRUE, print.auc=TRUE, print.auc.y=30)
legend("bottomright", legend=c("Model w/ all predictors", "Model Development with interactions", "Model Development no interactions",  "Simple Model (w/ OverTime)"), col = c("blue", "#4daf4a", "#e34a33", "#1c9099", "#1c9099"), lwd=2, cex = 0.75)
```

The above plot illustrates how the True Positive Rate (Sensitivity) behaves in relation with the False Positive Rate (1-Specificity).
In this paper we want to maximize the amount of correct classifications of people leaving the company i.e. True Positive Rate.
Thus we can take away from the above plot that including the interactions indeed makes sense, not solely to reach a higher Area Under the Curve (AUC), but also since a threshold of around ~90% on the True Positive Rate can reach a very similar False Positive Rate (around 25-30%) with a much simpler model (12 independent variables & 4 interactions vs 31 total independent variables). 

\newpage

# Conclusion

\newpage

# Session Information {.unnumbered}

```{r session-info}
sessionInfo()
```

\newpage

# References
